### Exercise 2a: Data: Strong Scalability

In this directory, there are store the data about the computation time, for the proposed custom algorithm and the official one, produced to obtain information about the differences in strong scalability between the two.

I have considered the necessary time to complete the broadcast, for both of the two algorithm, on a growing number of processes (from 4 to 64) in two different situations: when all of them are in the same node ("samenode_times") and when they are split between two nodes ("diffnode_times"). The problem size is fixed to an array of 5 integers to pass. The data file starting with "bcustom" are associated to the our custom algorithm, while the files with "bnative" contain data produced using the original algorithm. Obviously, different configurations and distributions of the processes inside the node and, especially the position of the two nodes in the diffnode case, effect the measured times. For these reasons, all of the configurations have been measured 200 time restarting each time the testing.

Inside this directory, I also left a Python Notebook containing all the code used to elaborate this time and to obtain the plots. It is completely commented, but the most important observations are also reported on the report. However, for some extras and to see the actual code used, please take a look to it.