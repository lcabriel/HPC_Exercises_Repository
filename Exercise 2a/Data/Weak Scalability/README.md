### Exercise 2a: Data: Weak Scalability

In this directory are store the data about the computation time for the proposed custom algorithm and the official one produced to obtain information about the differences in weak scalability between the two.
I have considered the necessary time to complete the broadcast for both of the two algorithm on a growing number of processes (from 4 to 32) in two different situations: when all of them are in the same node ("samenode_times") and when they are split between two nodes ("diffnode_times"). The work load per processor size is fixed to 4 integers to pass. Thus, when we will work with 4 processes we will pass between them an array of 16 intergers. The data file starting with "bcustom" are associated to the our custom algorithm while the files with "bnative" contain data produced using the original algorithm. Obviously different configurations and distributions of the processes inside the node and especially the position of the two nodes in the diffnode case effect the measured times. For these reasons all of the configurations have been measured 200 time restarting each time the testing.

Inside this directory I also left a Python Notebook containing all the code used to elaborate this time and to obtain the plots. It is completely commented but the most important observations are also reported on the report however for some extras and to see the actual code used, please take a look to it.