### Exercise 2c: Strong Scalability

In this directory are store the data about the computation time to obtain the strong scalability for the final version of the solution ("parallel_refactor") and for the solution implementing the naive parallel algorithm (parallel).

For the strong scalability, I have fixed the problem considering the complex domain $[-2.75,1.25]\times[-2,2]$ with a grid of 1600 pixel per axis and with an iteration cap of 30000. For each one of the two version, for different numbers of threads, I have run the associated code recording the execution time of each thread and the total execution time for the process. All this time data have been put in CSVs file with a run for each column and leaving in the last row the total time. This procedure has been repeated for different numbers of thread from 1 to 16. Obviously, having different number of threads implies that the CSVs have different number of rows: in fact if I have only a thread I will have 1+1 rows but for 10 threads will be 10+1 rows in the file. 

In this directory I have also inserted a Python Notebook ("time_elaborator.ipynb") containing all the elaborations of this time data and the plots. The observations about the results are also completely covered in the report however the single comment and the raw code are not reported there so if you are interested, please take a look.